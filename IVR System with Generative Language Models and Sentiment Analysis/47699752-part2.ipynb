{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8296c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Path to your audio file (e.g., 'audio.wav')\n",
    "audio_file_path = 'greet.mp3'\n",
    "\n",
    "# Load the audio file\n",
    "data, samplerate = sf.read(audio_file_path)\n",
    "\n",
    "# Play the audio file\n",
    "sd.play(data, samplerate)\n",
    "sd.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fecbefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording done\n",
      "Audio saved to recorded_audio.wav\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import wavio\n",
    "\n",
    "def record_audio(duration, sample_rate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    print(\"Recording done\")\n",
    "    return audio_data, sample_rate\n",
    "\n",
    "# Record 3 seconds of audio\n",
    "duration = 3  # seconds\n",
    "audio_data, sample_rate = record_audio(duration)\n",
    "\n",
    "# Save the audio to a file\n",
    "file_path = 'recorded_audio.wav'\n",
    "wavio.write(file_path, audio_data, sample_rate, sampwidth=2)\n",
    "print(f\"Audio saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d422f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript: I need a new\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = sr.AudioFile(file_path)\n",
    "\n",
    "    with audio_file as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        transcript = recognizer.recognize_google(audio_data)\n",
    "        return transcript\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Error occurred during speech recognition: {e}\"\n",
    "\n",
    "# Path to your audio file (e.g., 'audio.wav')\n",
    "user_response_audio_data = \"recorded_audio.wav\"\n",
    "\n",
    "# Transcribe the audio file\n",
    "user_response_transcript = transcribe_audio(user_response_audio_data)\n",
    "\n",
    "print(\"Transcript:\",user_response_transcript )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec09dc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "#MarieAngeA13/Sentiment-Analysis-BERT\n",
    "from transformers import pipeline\n",
    "m='MarieAngeA13/Sentiment-Analysis-BERT'\n",
    "classifier = pipeline('sentiment-analysis', model=m)\n",
    "results=classifier(user_response_transcript)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0adfe5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9399674534797668}]\n"
     ]
    }
   ],
   "source": [
    "# Check if the label is very negative\n",
    "if results[0]['label'] == 'negative' and results[0]['score'] > 0.9:  # Adjust the threshold as needed\n",
    "    print(\"operator\")\n",
    "    exit()\n",
    "else:\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201e01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confused\n"
     ]
    }
   ],
   "source": [
    "# Sample few-shot data with keywords for each category\n",
    "few_shot_data = {\n",
    "    'Account related Enquiries': ['address', 'change', 'contact number', 'subscription','cancel','roaming'],\n",
    "    'Technical Enquiries' : ['nonfunctional', 'service', 'working','unhappy'],\n",
    "    'New Enquiries': ['new sim', 'products','device',\"buy\"]}\n",
    "\n",
    "\n",
    "\n",
    "# Function to predict category based on keywords\n",
    "def predict_category(script, few_shot_data):\n",
    "    max_matches = 0\n",
    "    predicted_category = None\n",
    "    for category, keywords in few_shot_data.items():\n",
    "        matches = sum(keyword in script.lower() for keyword in keywords)\n",
    "        if matches > max_matches:\n",
    "            max_matches = matches\n",
    "            predicted_category = category\n",
    "            \n",
    "    return predicted_category\n",
    "\n",
    "\n",
    "# Test script\n",
    "\n",
    "\n",
    "# Predict category\n",
    "predicted_category = predict_category(user_response_transcript, few_shot_data)\n",
    "if predicted_category is None:\n",
    "    print(\"Confused\")\n",
    "else:\n",
    "    print(\"Predicted category:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704b3c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "# Path to your audio files\n",
    "account_related_inquiry_audio_path = 'Account_related_inquiries.mp3'\n",
    "technical_audio_path = 'Technical_audio.mp3'\n",
    "\n",
    "new_enquiry_audio_path = 'sales_audio.mp3'\n",
    "confused_audio_path = 'Confused_audio.mp3'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Determine the audio file path based on the predicted label\n",
    "if predicted_category == 'Account related Enquiries':\n",
    "    audio_file_path = account_related_inquiry_audio_path\n",
    "elif predicted_category == 'Technical Enquiries':\n",
    "    audio_file_path = technical_audio_path\n",
    "elif predicted_category == 'New Enquiries':\n",
    "    audio_file_path = new_enquiry_audio_path \n",
    "else:\n",
    "    audio_file_path = confused_audio_path\n",
    "\n",
    "# Load the audio file\n",
    "data, samplerate = sf.read(audio_file_path)\n",
    "\n",
    "# Play the audio file\n",
    "sd.play(data, samplerate)\n",
    "sd.wait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2562f82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording done\n",
      "Audio saved to recorded_audio_1.wav\n",
      "Transcript: Speech recognition could not understand the audio\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def record_audio(duration, sample_rate=44100):\n",
    "    print(\"Recording...\")\n",
    "    audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.int16)\n",
    "    sd.wait()\n",
    "    print(\"Recording done\")\n",
    "    return audio_data, sample_rate\n",
    "\n",
    "# Record 3 seconds of audio\n",
    "duration = 3  # seconds\n",
    "audio_data, sample_rate = record_audio(duration)\n",
    "\n",
    "# Save the audio to a file\n",
    "file_path = 'recorded_audio_1.wav'\n",
    "wavio.write(file_path, audio_data, sample_rate, sampwidth=2)\n",
    "print(f\"Audio saved to {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_file = sr.AudioFile(file_path)\n",
    "\n",
    "    with audio_file as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "        transcript = recognizer.recognize_google(audio_data)\n",
    "        return transcript\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech recognition could not understand the audio\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Error occurred during speech recognition: {e}\"\n",
    "\n",
    "# Path to your audio file (e.g., 'audio.wav')\n",
    "user_response_audio_data = \"recorded_audio_1.wav\"\n",
    "\n",
    "# Transcribe the audio file\n",
    "user_response_transcript_1 = transcribe_audio(user_response_audio_data)\n",
    "\n",
    "print(\"Transcript:\",user_response_transcript_1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04b5dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confused\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Sample transcript\n",
    "\n",
    "\n",
    "# Classify the transcript using zero-shot learning\n",
    "classification = classifier(user_response_transcript_1, [\"affirmative\", \"negative\"])\n",
    "\n",
    "# Check if the response is affirmative\n",
    "if classification[\"labels\"][0] == \"affirmative\":\n",
    "    print(predicted_category)\n",
    "else:\n",
    "    print(\"Confused\")\n",
    "\n",
    "closing_audio=\"Goodbye.mp3\"\n",
    "    \n",
    "# Load the audio file\n",
    "data, samplerate = sf.read(closing_audio)\n",
    "\n",
    "# Play the audio file\n",
    "sd.play(data, samplerate)\n",
    "sd.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3044e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
